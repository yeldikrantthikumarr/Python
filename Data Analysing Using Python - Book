# Python
Machine Learning using Python
import numpy as np
p = np.array([48.858598, 2.294495])
p
Output: array([48.858598, 2.294495])

import numpy as np

p.ndim # getting dimension of array p
1
p.shape # getting size of each array dimension
(2,)
len(p) # getting dimension length of array p
2
p.dtype # getting data type of array p
dtype('float64')

a = np.array([1, 2, 3, 4])
a.dtype
dtype('int64')
float_b = a.astype(np.float64)
float_b.dtype
dtype('float64')

a = np.arange(7)
a
array([0, 1, 2, 3, 4, 5, 6])
a[1], a [4], a[-1]
(1, 4, 6)

a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
a[0, 2] # first row, third column
3
a[0, 2] = 10
a
array([[1, 2, 10], [4, 5, 6], [7, 8, 9]])
b = a[2]
b
array([7, 8, 9])
c = a[:2]
c
array([[1, 2, 10], [4, 5, 6]])


b[-1] = 11
a
array([[1, 2, 10], [4, 5, 6], [7, 8, 11]])

a = np.array([3, 5, 1, 10])
b = (a % 5 == 0)
b
array([False, True, False, True], dtype=bool)
c = np.array([[0, 1], [2, 3], [4, 5], [6, 7]])
c[b]
array([[2, 3], [6, 7]])

#The second example is an illustration of using integer masks on arrays#

a = np.array([[1, 2, 3, 4],
[5, 6, 7, 8],
[9, 10, 11, 12],
[13, 14, 15, 16]])
a[[2, 1]]
array([[9, 10, 11, 12], [5, 6, 7, 8]])
a[[-2, -1]] # select rows from the end
array([[ 9, 10, 11, 12], [13, 14, 15, 16]])
a[[2, 3], [0, 1]] # take elements at (2, 0) and (3, 1)
array([9, 14])

#Scalar operations will propagate the value to each element of the array#
a = np.ones(4)
a * 2
array([2., 2., 2., 2.])
a + 3
array([4., 4., 4., 4.])

#All arithmetic operations between arrays apply the operation element wise#

a = np.ones([2, 4])
a * a
array([[1., 1., 1., 1.], [1., 1., 1., 1.]])
a + a
array([[2., 2., 2., 2.], [2., 2., 2., 2.]])

#Some examples of comparisons and logical operations#

a = np.array([1, 2, 3, 4])
b = np.array([1, 1, 5, 3])
a == b
array([True, False, False, False], dtype=bool)
np.array_equal(a, b) # array-wise comparison
False
c = np.array([1, 0])
d = np.array([1, 1])
np.logical_and(c, d) # logical operations
array([True, False])

a = np.array([[0, 5, 10], [20, 25, 30]])
a.reshape(3, 2)
array([[0, 5], [10, 20], [25, 30]])
a.T
array([[0, 20], [5, 25], [10, 30]])


a = np.array([[[0, 1, 2], [3, 4, 5]],
[[6, 7, 8], [9, 10, 11]]])
a.swapaxes(1, 2)
array([[[0, 3],
[1, 4],
[2, 5]],
[[6, 9],
[7, 10],
[8, 11]]])

a = np.array([[1, 2, 3],[4,5,6]])
np.dot(a.T, a)
array([[17, 22, 27],
[22, 29, 36],
[27, 36, 45]])

a = np.array ([[6, 34, 1, 6], [0, 5, 2, -1]])
np.sort(a) # sort along the last axis
array([[1, 6, 6, 34], [-1, 0, 2, 5]])
np.sort(a, axis=0) # sort along the first axis
array([[0, 5, 1, -1], [6, 34, 2, 6]])
b = np.argsort(a) # fancy indexing of sorted array
b
array([[2, 0, 3, 1], [3, 0, 2, 1]])
a[0][b[0]]
array([1, 6, 6, 34])
np.argmax(a) # get index of maximum element
1

a = np.array([[0, 1, 2], [3, 4, 5]])
np.save('test1.npy', a)

##If we want to store several arrays into a single file in an uncompressed .npz format,
#we can use the np.savez function, as shown in the following example:

a = np.arange(4)
b = np.arange(7)
np.savez('test2.npz', arr0=a, arr1=b)

#The .npz file is a zipped archive of files named after the variables they contain.
#When we load an .npz file, we get back a dictionary-like object that can be queried

for its lists of arrays:
dic = np.load('test2.npz')
dic['arr0']
array([0, 1, 2, 3])

#Another way to save array data into a file is using the np.savetxt function that
#allows us to set format properties in the output file:
x = np.arange(4)
# e.g., set comma as separator between elements
np.savetxt('test3.out', x, delimiter=',')

np.load('test1.npy')
array([[0, 1, 2], [3, 4, 5]])
np.loadtxt('test3.out', delimiter=',')
array([0., 1., 2., 3.])

A = np.array([[1, 4, 6],
[5, 2, 2],
[-1, 6, 8]])
w, v = np.linalg.eig(A)
w # eigenvalues
array([-0.111 + 1.5756j, -0.111 – 1.5756j, 11.222+0.j])
v # eigenvector
array([[-0.0981 + 0.2726j, -0.0981 – 0.2726j, 0.5764+0.j],
[0.7683+0.j, 0.7683-0.j, 0.4591+0.j],
[-0.5656 – 0.0762j, -0.5656 + 0.00763j, 0.6759+0.j]])


A = np.array([[1, 4, 6], [5, 2, 2], [-1, 6, 8]])
b = np.array([[1], [2], [3]])
x = np.linalg.solve(A, b)
x
array([[-1.77635e-16], [2.5], [-1.5]])

#NumPy random numbers#

np.random.seed(20)
#An array of random numbers in the [0.0, 1.0] interval can be generated as follows:
np.random.rand(5)
array([0.5881308, 0.89771373, 0.89153073, 0.81583748,
0.03588959])
np.random.rand(5)
array([0.69175758, 0.37868094, 0.51851095, 0.65795147,
0.19385022])
np.random.seed(20) # reset seed number
np.random.rand(5)
array([0.5881308, 0.89771373, 0.89153073, 0.81583748,
0.03588959])
#If we want to generate random integers in the half-open interval [min, max],we can user the randint(min, max, length) function:
np.random.randint(10, 20, 5)
array([17, 12, 10, 16, 18])

#sort a list in a random order#
a = np.arange(10)
np.random.shuffle(a)
a
array([7, 6, 3, 1, 4, 2, 5, 0, 9, 8])

#Chapter3- Data Analysis with Pandas

import pandas as pd
import numpy as np

#Series#

s1 = pd.Series(np.random.rand(4),
index=['a', 'b', 'c', 'd'])
s1
a 0.6122
b 0.98096
c 0.3350
d 0.7221
dtype: float64

s2 = pd.Series(np.random.rand(4))
s2
0 0.6913
1 0.8487
2 0.8627
3 0.7286
dtype: float64

s1['c']
0.3350
s1['c'] = 3.14
s1['c', 'a', 'b']
c 3.14
a 0.6122
b 0.98096

s3 = pd.Series({'001': 'Nam', '002': 'Mary',
'003': 'Peter'})
s3
001 Nam
002 Mary
003 Peter
dtype: object
    
s4 = pd.Series({'001': 'Nam', '002': 'Mary',
'003': 'Peter'}, index=[
'002', '001', '024', '065'])
s4
002 Mary
001 Nam
024 NaN
065 NaN
dtype: object
ect
pd.isnull(s4)
002 False
001 False
024 True
065 True
dtype: bool
    
    
s5 = pd.Series(2.71, index=['x', 'y'])
s5
x 2.71
y 2.71
dtype: float64
    

s6 = pd.Series(np.array([2.71, 3.14]), index=['z', 'y'])
s6
z 2.71
y 3.14
dtype: float64
s5 + s6
x NaN
y 5.85
z NaN
dtype: float64
data = {'Year': [2000, 2005, 2010, 2014],
'Median_Age': [24.2, 26.4, 28.5, 30.3],

'Density': [244, 256, 268, 279]}
df1 = pd.DataFrame(data)
df1

df2 = pd.DataFrame(data, columns=['Year', 'Density',
'Median_Age'])
df2

df2.index
Int64Index([0, 1, 2, 3], dtype='int64')


df3 = pd.DataFrame(data, columns=['Year', 'Density',
'Median_Age'], index=['a', 'b', 'c', 'd'])
df3.index
Index([u'a', u'b', u'c', u'd'], dtype='object')

df4 = pd.DataFrame([
['Peter', 16, 'pupil', 'TN', 'M', None],
['Mary', 21, 'student', 'SG', 'F', None],
['Nam', 22, 'student', 'HN', 'M', None],
['Mai', 31, 'nurse', 'SG', 'F', None],
['John', 28, 'laywer', 'SG', 'M', None]],
columns=['name', 'age', 'career', 'province', 'sex', 'award'])

df4.name # or df4['name']
0 Peter
1 Mary
2 Nam
3 Mai
4 John
Name: name, dtype: object

df4['award'] = None
df4

df4.ix[1]
name Mary
age 21
career student
province SG
sex F
award None
Name: 1, dtype: object
        
df4 = pd.read_csv('person.csv')
df4


#Reindexing and altering labels

s2.reindex([0, 2, 'b', 3])
0 0.6913
2 0.8627
b NaN
3 0.7286
dtype: float64

df1.reindex(index=[0, 2, 'b', 3],
columns=['Density', 'Year', 'Median_Age','C'])
Density Year Median_Age C
0 244 2000 24.2 NaN
2 268 2010 28.5 NaN
b NaN NaN NaN NaN
3 279 2014 30.3 NaN

#Head and tail

s7 = pd.Series(np.random.rand(10000))
s7.head()
0 0.631059
1 0.766085
2 0.066891
3 0.867591
4 0.339678

dtype: float64
s7.tail(3)
9997 0.412178
9998 0.800711
9999 0.438344
dtype: float64


#Function application

df5.apply(np.std, axis=1) # default: axis=0
0 0.816497
1 0.816497
2 0.816497
dtype: float64
    
f = lambda x: x.max() – x.min() # step 1
df5.apply(f, axis=1) # step 2
0 2
1 2
2 2
dtype: int64
def sigmoid(x):
return 1/(1 + np.exp(x))
df5.apply(sigmoid)
a b c
0 0.500000 0.268941 0.119203
1 0.047426 0.017986 0.006693
2 0.002473 0.000911 0.000335

#Sorting

df7 = pd.DataFrame(np.arange(12).reshape(3,4),
columns=['b', 'd', 'a', 'c'],
index=['x', 'y', 'z'])
df7
  b d a c
x 0 1 2 3
y 4 5 6 7
z 8 9 10 11

df7.sort_index(axis=1)
  a b c d
x 2 0 3 1
y 6 4 7 5
z 10 8 11 9

s4.order(na_position='first')
024 NaN
065 NaN
002 Mary
001 Nam
dtype: object
s4
002 Mary
001 Nam
024 NaN
065 NaN
dtype: object
    
s4.sort(na_position='first')
s4
024 NaN
065 NaN
002 Mary
001 Nam
dtype: object
    
df7.sort(['b', 'd'], ascending=False)
   b d a c
z 8 9 10 11
y 4 5 6 7
x 0 1 2 3

#Indexing and Selecting Data

s4[['024', '002']] # selecting data of Series object
024 NaN
002 Mary
dtype: object
s4[['024', '002']] = 'unknown' # assigning data
s4
024 unknown
065 NaN
002 unknown
001 Nam
dtype: object

df5[['b', 'c']]
  b c
0 1 2
1 4 5
2 7 8

df5.ix[0]
a 0
b 1
c 2
Name: 0, dtype: int64
df5.ix[0, 1:3]
b 1
c 2
Name: 0, dtype: int64

s1 = pd.Series(np.random.rand(3))
s1
Data Analysis with Pandas
[ 48 ]
0 0.460324
1 0.993279
2 0.032957
dtype: float64
s2 = pd.Series(np.random.rand(3))
s2
0 0.777509
1 0.573716
2 0.664212
dtype: float64
s1.cov(s2)
-0.024516360159045424
df8 = pd.DataFrame(np.random.rand(12).reshape(4,3),
columns=['a','b','c'])
df8
      a         b      c
0 0.200049 0.070034 0.978615
1 0.293063 0.609812 0.788773
2 0.853431 0.243656 0.978057
0.985584 0.500765 0.481180
df8.cov()
    a            b        c
a 0.155307 0.021273 -0.048449
b 0.021273 0.059925 -0.040029
c -0.048449 -0.040029 0.055067

df8.corr(method = 'spearman')
     a b c
a 1.0 0.4 -0.8
b 0.4 1.0 -0.8
c -0.8 -0.8 1.0

df9 = pd.DataFrame(np.arange(8).reshape(4,2),
columns=['a', 'b'])
df9

a b
0 0 1
1 2 3
2 4 5
3 6 7
df8.corrwith(df9)
a 0.955567
b 0.488370
c NaN
dtype: float64

#Working with missing data

df8 = pd.DataFrame(np.arange(12).reshape(4,3),
columns=['a', 'b', 'c'])
  a b c
0 0 1 2
1 3 4 5
2 6 7 8
3 9 10 11
df9 = df8.reindex(columns = ['a', 'b', 'c', 'd'])
 a b c d
0 0 1 2 NaN
1 3 4 5 NaN
2 6 7 8 NaN
4 9 10 11 NaN

df10 = df8.reindex([3, 2, 'a', 0])
a b c
3 9 10 11
2 6 7 8
a NaN NaN NaN
0 0 1 2

df10.isnull()
 a b c
3 False False False
2 False False False
a True True True
0 False False False

s4 = pd.Series({'001': 'Nam', '002': 'Mary',
'003': 'Peter'},
index=['002', '001', '024', '065'])
s4
002 Mary
001 Nam
024 NaN
065 NaN
dtype: object
s4.dropna() # dropping all null value of Series object
002 Mary
001 Nam
dtype: object
    
f9.dropna() # all rows will be dropped
Empty DataFrame
Columns: [a, b, c, d]
Index: []
df9.dropna(axis=1)
 a b c
0 0 1 2
1 3 4 5
2 6 7 8
3 9 10 11

df11 = df8.reindex([3, 2, 'a', 0], fill_value = 0)
df11
   a b c
3 9 10 11
2 6 7 8
a 0 0 0
0 0 1 2

df9.fillna(-1)
 a b c d
0 0 1 2 -1
1 3 4 5 -1
2 6 7 8 -1
3 9 10 11 -1

#Hierarchical indexing

s8 = pd.Series(np.random.rand(8), index=[['a','a','b','b','c','c',
'd','d'], [0, 1, 0, 1, 0,1, 0, 1, ]])
s8
a 0 0.721652
1 0.297784
b 0 0.271995
1 0.125342
c 0 0.444074
1 0.948363
d 0 0.197565
1 0.883776
dtype: float64
    
s8.unstack()
      0      1
a 0.549211 0.420874
b 0.051516 0.715021
c 0.503072 0.720772
d 0.373037 0.207026

df = pd.DataFrame(np.random.rand(12).reshape(4,3),
index=[['a', 'a', 'b', 'b'],
[0, 1, 0, 1]],
columns=[['x', 'x', 'y'], [0, 1, 0]])
df
x y
0 1 0
a 0 0.636893 0.729521 0.747230
1 0.749002 0.323388 0.259496
b 0 0.214046 0.926961 0.679686
0.013258 0.416101 0.626927
df.index
MultiIndex(levels=[['a', 'b'], [0, 1]],
labels=[[0, 0, 1, 1], [0, 1, 0, 1]])
df.columns
MultiIndex(levels=[['x', 'y'], [0, 1]],
labels=[[0, 0, 1], [0, 1, 0]])


df['x']
0 1
a 0 0.636893 0.729521
1 0.749002 0.323388
b 0 0.214046 0.926961
0.013258 0.416101
df[[0]]
 x
 0
a 0 0.636893
1 0.749002
b 0 0.214046
0.013258

df.ix['a', 'x']
0 1
0 0.636893 0.729521
0.749002 0.323388
df.ix['a','x'].ix[1]
0 0.749002
1 0.323388
Name: 1, dtype: float64
        
df.std(level=1)
x y
0 1 0
0 0.298998 0.139611 0.047761
0.520250 0.065558 0.259813
df.std(level=0)
x y
0 1 0
a 0.079273 0.287180 0.344880
b 0.141979 0.361232 0.037306

#Panel data

panel = pd.Panel(np.random.rand(2, 4, 5),
items = ['item1', 'item2'])
panel
<class 'pandas.core.panel.Panel'>
Dimensions: 2 (items) x 4 (major_axis) x 5 (minor_axis)
Items axis: item1 to item2
Major_axis axis: 0 to 3
Minor_axis axis: 0 to 4
df1 = pd.DataFrame(np.arange(12).reshape(4, 3),
columns=['a','b','c'])
df1
  a b c
0 0 1 2
1 3 4 5
2 6 7 8
9 10 11
df2 = pd.DataFrame(np.arange(9).reshape(3, 3),
columns=['a','b','c'])
df2
  a b c
0 0 1 2
1 3 4 5
6 7 8
# create another Panel from a dict of DataFrame objects
panel2 = pd.Panel({'item1': df1, 'item2': df2})
panel2
<class 'pandas.core.panel.Panel'>
Dimensions: 2 (items) x 4 (major_axis) x 3 (minor_axis)
Items axis: item1 to item2
Major_axis axis: 0 to 3
Minor_axis axis: a to c

panel2['item1']
  a b c
0 0 1 2
1 3 4 5
2 6 7 8
3 9 10 11

panel2.ix[:, 1:3, ['b', 'c']]
<class 'pandas.core.panel.Panel'>
Dimensions: 2 (items) x 3 (major_axis) x 2 (minor_axis)
Items axis: item1 to item2
Major_axis axis: 1 to 3
Minor_axis axis: b to c
panel2.ix[:, 2, :]
 item1 item2
a 6     6
b 7     7
c 8     8


#Data Visualization

import matplotlib.pyplot as plt
from numpy import *
x = linspace(0, 3, 6)
x
array([0., 0.6, 1.2, 1.8, 2.4, 3.])
y = power(x,2)
y
array([0., 0.36, 1.44, 3.24, 5.76, 9.])
figure()
plot(x, y, 'r')
xlabel('x')
ylabel('y')
title('Data visualization in MATLAB-like API')
plt.show()

import matplotlib.pyplot as plt
The preceding example could then be written as follows:
plt.plot(x, y)
plt.xlabel('x')
plt.ylabel('y')
plt.title('Data visualization using Pyplot of Matplotlib')
plt.show()


plt.plot(y)
plt.xlabel('x')
plt.ylabel('y')
plt.title('Plot y value without given x values')
plt.show()

plt.axis([0, 6, 0, 12])

#Line properties

plt.plot(x*2, 'g^', x*3, 'rs', x**x, 'y-')
plt.axis([0, 6, 0, 30])
plt.show()

line = plt.plot(y, color='red', linewidth=2.0)
line.set_linestyle('--')
plt.setp(line, marker='o')
plt.show()

#Figures and subplots
plt.figure('a') # define a figure, named 'a'
plt.subplot(221) # the first position of 4 subplots in 2x2 figure
plt.plot(y+y, 'r--')
plt.subplot(222) # the second position of 4 subplots
plt.plot(y*3, 'ko')
plt.subplot(223) # the third position of 4 subplots
plt.plot(y*y, 'b^')
plt.subplot(224)
plt.show()


plt.figure('a')
plt.subplot(222)
plt.title('visualization of y*3')
plt.show()

plt.figure('b') # create another figure, named 'b'
ax1 = plt.axes([0.05, 0.1, 0.4, 0.32])
ax2 = plt.axes([0.52, 0.1, 0.4, 0.32])
ax3 = plt.axes([0.05, 0.53, 0.87, 0.44])
plt.show()

#Scatter Plots

X = np.random.normal(0, 1, 1000)
Y = np.random.normal(0, 1, 1000)
plt.scatter(X, Y, c = ['b', 'g', 'k', 'r', 'c'])
plt.show()

#Bar Plots

X = np.arange(5)
Y = 3.14 + 2.71 * np.random.rand(5)
plt.subplots(2)
# the first subplot
plt.subplot(211)
plt.bar(X, Y, align='center', alpha=0.4, color='y')
plt.xlabel('x')
plt.ylabel('y')
plt.title('bar plot in vertical')
# the second subplot
plt.subplot(212)
plt.barh(X, Y, align='center', alpha=0.4, color='c')
plt.xlabel('x')
plt.ylabel('y')
plt.title('bar plot in horizontal')
plt.show()


#Contour Plots

x = np.linspace(-1, 1, 255)
y = np.linspace(-2, 2, 300)
z = np.sin(y[:, np.newaxis]) * np.cos(x)
plt.contour(x, y, z, 255, linewidth=2)
plt.show()

#Histogram Plots

mu, sigma = 100, 25
fig, (ax0, ax1) = plt.subplots(ncols=2)
x = mu + sigma * np.random.randn(1000)
ax0.hist(x,20, normed=1, histtype='stepfilled',
facecolor='g', alpha=0.75)
ax0.set_title('Stepfilled histogram')
ax1.hist(x, bins=[100,150, 165, 170, 195] normed=1,
histtype='bar', rwidth=0.8)
ax1.set_title('uniquel bins histogram')
# automatically adjust subplot parameters to give specified padding
plt.tight_layout()
plt.show()


#Legends and annotations

x = np.linspace(0, 1, 20)
y1 = np.sin(x)
y2 = np.cos(x)
y3 = np.tan(x)
plt.plot(x, y1, 'c', label='y=sin(x)')
plt.plot(x, y2, 'y', label='y=cos(x)')
plt.plot(x, y3, 'r', label='y=tan(x)')
plt.lengend(loc='upper left')
plt.show()

p1 = plt.plot(x, y1, 'c', label='y=sin(x)')
p2 = plt.plot(x, y2, 'y', label='y=cos(x)')
p3 = plt.plot(x, y3, 'r', label='y=tan(x)')
lsin = plt.legend(handles=p1, loc='lower right')
lcos = plt.legend(handles=p2, loc='upper left')
ltan = plt.legend(handles=p3, loc='upper right')
# with above code, only 'y=tan(x)' legend appears in the figure
# fix: add lsin, lcos as separate artists to the axes
plt.gca().add_artist(lsin)
plt.gca().add_artist(lcos)
# automatically adjust subplot parameters to specified padding
plt.tight_layout()
plt.show()

x = np.linspace(-2.4, 0.4, 20)
y = x*x + 2*x + 1
plt.plot(x, y, 'c', linewidth=2.0)
plt.text(-1.5, 1.8, 'y=x^2 + 2*x + 1',
fontsize=14, style='italic')
plt.annotate('minima point', xy=(-1, 0),
xytext=(-1, 0.3),
horizontalalignment='center',
verticalalignment='top',
arrowprops=dict(arrowstyle='->',
connectionstyle='arc3'))
plt.show() 

p1 = plt.plot (x, y1, 'c', label='y=sin(x)')
p2 = plt.plot (x, y2, 'y', label='y=cos(x)')
p3 = plt.plot (x, y3, 'r', label='y=tan(x)')
lsin = plt.legend(handles=p1, loc='lower right')
lcos = plt.legend(handles=p2, loc='upper left')
ltan = plt.legend(handles=p3, loc='upper right')
# with above code, only 'y=tan(x)' legend appears in the figure
# fix: add lsin, lcos as separate artists to the axes
plt.gca() .add_artist(lsin)
plt.gca() .add_artist(lcos)
# automically adjust subplot parameters to specified padding 
plt.tight_layout()
plt.show()



x = np.silence(-2.4, 0.4, 20)
y= x*x + 2*x + 1
plt.plot(x, y, 'c', linewidth=2.0)
plt.text(-1.5, 1.8, 'y=x^2 + 2*x + 1', fontsize=14, style='italic')
plt.annotate('minima point', xy=(-1, 0), xytext=(-1, 0.3), horizantalalignment='center', verticalalignment='top', arrowprops=dict(arrowstyle='->', connectionstyle='arc3'))
plt.show()


#Plotting functions with Pandas



s = pd.Series(np.random.normal(10, 8, 20))
s.plot(style='ko-', alpha=0.4, label='Series plotting')
plt.legend()
plt.show()



data = {'Median_Age': [24.2, 26.4, 28.5, 30.3], 'Density': [244, 256, 268, 279]}
index_label = ['2000', '2005', '2010', '2014'];
df1 = pd.DataFrame(data, index=index_label)
df1.plot(kind='bar', subplots=True, sharex=True)
plt.tight_layout();
plt.show() 

data = {'Median_Age': [24.2, 26.4, 28.5, 30.3],
'Density': [244, 256, 268, 279]}
index_label = ['2000', '2005', '2010', '2014'];
df1 = pd.DataFrame(data, index=index_label)
df1.plot(kind='bar', subplots=True, sharex=True)
plt.tight_layout();
plt.show()

#Chapter5-Time Series 

#Working with date and time objects

import datetime
datetime.datetime(2000, 1, 1)

datetime.datetime.strptime("2000/1/1", "%Y/%m/%d") 

datetime.datetime(2000, 1, 1, 0, 0).strftime("%Y%m%d")

import pandas as pd
import numpy as np
pd.to_datetime("4th of July")
pd.to_datetime("13.01.2000")
pd.to_datetime("7/8/2000")
pd.to_datetime("7/8/2000", dayfirst=True)
issubclass(pd.Timestamp, datetime.datetime) 

ts = pd.to_datetime(946684800000000000)
ts.year, ts.month, ts.day, ts.weekday() (2000, 1, 1, 5)

index = [pd.Timestamp("2000-01-01"),pd.Timestamp("2000-01-02"),pd.Timestamp("2000-01-03")]
ts = pd.Series(np.random.randn(len(index)), index=index)
ts

ts.indexDatetime


ts = pd.Series(np.random.randn(len(index)), index=["2000-01-01", "2000-01-02", "2000-01-03"])
ts.index
Index([u'2000-01-01', u'2000-01-02', u'2000-01-03'], dtype='object')

index = pd.to_datetime(["2000-01-01", "2000-01-02", "2000-01-03"])
ts = pd.Series(np.random.randn(len(index)), index=index)
ts.index

pd.date_range(start="2000-01-01", periods=3, freq='H')

pd.date_range(start="2000-01-01", periods=3, freq='T')

pd.date_range(start="2000-01-01", periods=3, freq='S')

pd.date_range(start="2000-01-01", periods=3, freq='B')

pd.date_range(start="2000-01-01", periods=5, freq='1D1h1min10s')

pd.date_range(start="2000-01-01", periods=5, freq='12BH')

ts.index

pd.date_range(start="2000-01-01", periods=5, freq=12 * bh)

pd.date_range(start="2000-01-01", periods=5, freq='W-FRI')

pd.date_range(start="2000-01-01", periods=5, freq='WOM-2TUE')


s = pd.date_range(start="2000-01-01", periods=10, freq='BAS-JAN')
t = pd.date_range(start="2000-01-01", periods=10, freq='A-FEB')
s.union(t)


index = pd.date_range(start='2000-01-01', periods=200, freq='B')
ts = pd.Series(np.random.randn(len(index)), index=index)
walk = ts.cumsum()
walk.plot()

ts.head()

ts[0]

ts[1:3]

ts['2000-01-03']

ts[datetime.datetime(2000, 1, 3)]

ts['2000-01-03':'2000-01-05']

ts['2000-01-03':datetime.datetime(2000, 1, 5)]


ts['2000-01-03':datetime.date(2000, 1, 5)]

ts['2000-02']


ts['2000-03':'2000-05']

small_ts = ts['2000-02-01':'2000-02-05']

small_ts

small_ts.shift(2)


small_ts.shift(-2)


#Downsampling Time Series Data


rng = pd.date_range('4/29/2015 8:00', periods=600, freq='T')

ts = pd.Series(np.random.randint(0, 100, len(rng)), index=rng)
ts.head()

ts.resample('10min').head()

ts.resample('10min', how='sum') .head()
ts.resample('1h', how='sum') .head()
ts.resample('1h', how='max') .head()
import random
ts.resample('1h', how=lambda m: random.choice(m)) .head()


ts.resample('1h', how='ohlc') .head()


#Unsampling Time Series Data

rng = pd.date_range('4/29/2015 8:00', periods=10, freq='H')
ts = pd.Series(np.random.randint(0, 100, len(rng)), index=rng)
ts.head()

ts.resample('15min')
ts.head()

ts.resample('15min', fill_method='ffill').head()
ts.resample('15min', fill_method='bfill').head()


tsx = ts.resample('15min')
tsx.interpolate() .head()

ts.resample('15min', fill_method='ffill', limit2). head()
ts.resample('15min', fill_method='ffill', limit=2, loffset='5min').head()

tsx = ts.resample('15min')
tsx.interpolate().head()



#Time Zone Handling

t = pd.Timestamp('2000-01-01')
t.tz is None

t = pd.Timestamp('2000-01-01', tz='Europe/Berlin')
t.tz

rng = pd.date_range('1/1/2000 00:00', periods=10, freq='D',
tz='Europe/London')
rng
DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04','2000-01-05', '2000-01-06', '2000-01-07', '2000-01-08','2000-01-09', '2000-01-10'],
dtype='datetime64[ns]', freq='D', tz='Europe/London')

import pytz
tz = pytz.timezone('Europe/London')
rng = pd.date_range('1/1/2000 00:00', periods=10, freq='D', tz=tz)
rng
DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04','2000-01-05', '2000-01-06', '2000-01-07', '2000-01-08','2000-01-09', '2000-01-10'],
dtype='datetime64[ns]', freq='D', tz='Europe/London')



rng = pd.date_range('1/1/2000 00:00', periods=10, freq='D')
ts = pd.Series(np.random.randn(len(rng)), rng)
ts.index.tz is None
True
ts_utc = ts.tz_localize('UTC')
ts_utc.index.tz

ts_utc.tz_convert('Europe/Berlin').index.tz

ts_utc.tz_convert(None).index.tz is None

ts_utc.tz_localize(None).index.tz is None


#TimeDeltas

pd.Timedelta('1 days')

pd.Timedelta('-1 days 2 min 10s 3us')

pd.Timedelta(days=1,seconds=1)

pd.Timedelta(days=1) + pd.Timedelta(seconds=1)

pd.to_timedelta('20.1s')

pd.to_timedelta(np.arange(7), unit='D')


#Time Series Plotting

rng = pd.date_range(start='2000', periods=120, freq='MS')
ts = pd.Series(np.random.randint(-10, 10, size=len(rng)), rng).
cumsum()
ts.head()


ts.plot(c='k', title='Example time series')
plt.show()

ts.resample('2A').plot(c='0.75', ls='--')
ts.resample('5A').plot(c='0.25', ls='-.')

plt.clf()
tsx = ts.resample('1A')
ax = tsx.plot(kind='bar', color='k')
ax.set_xticklabels(tsx.index.year)plt.clf()


ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000',
periods=1000))
df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,
columns=['A', 'B', 'C', 'D'])


df = df.cumsum()
df.plot(color=['k', '0.75', '0.5', '0.25'], ls='--')


#Chapter6-Interacting with datebases


df_ex1 = pd.read_csv('example_data/ex_06-01.txt')
df_ex1

df_ex2 = pd.read_csv('example_data/ex_06-02.txt', sep = '\t', header=None)
df_ex2

df_ex3 = pd.read_csv('example_data/ex_06-02.txt', sep = '\t', header=None, index_col=0)
df_ex3


import csv
f = open('data/ex_06-03.txt')
r = csv.reader(f, delimiter='\t')
for line in r:
print(line)

df_ex3.to_csv('example_data/ex_06-02.out', sep = ';')

import sys
df_ex3.to_csv(sys.stdout, sep='\t', header=False, index=False)

df_ex3.to_csv(sys.stdout, columns=[3,1,4], header=False, sep='\t')


df_ex3.to_pickle('example_data/ex_06-03.out')
pd.read_pickle('example_data/ex_06-03.out')


#HDF5

store = pd.HDFStore('hdf5_store.h5')
store <class 'pandas.io.pytables.HDFStore'>
File path: hdf5_store.h5
Empty

store['ex3'] = df_ex3
store['name'] = df_ex2[0]
store['hometown'] = df_ex3[4]
store
<class 'pandas.io.pytables.HDFStore'>
File path: hdf5_store.h5

store['name']

store.close()
store
<class 'pandas.io.pytables.HDFStore'>
File path: hdf5_store.h5
File is CLOSED

#Interacting with data in MongoDB


import pymongo
conn = pymongo.MongoClient(host='localhost', port=27017)

conn.database_names()
['local']
lc = conn.local
lc


db = conn.db
db

lc.collection_names()
['startup_log', 'system.indexes']
db.collection_names()
[]


collection = db.person
collection
Collection(Database(MongoClient('localhost', 27017), 'db'), 'person')
# insert df_ex2 DataFrame into created collection
import json
records = json.load(df_ex2.T.to_json()).values()
records

collection.insert(records)
[ObjectId('557da218f21c761d7c176a40'), ObjectId('557da218f21c761d7c176a41'), ObjectId('557da218f21c761d7c176a42'), ObjectId('557da218f21c761d7c176a43'), ObjectId('557da218f21c761d7c176a44'), ObjectId('557da218f21c761d7c176a45'),
ObjectId('557da218f21c761d7c176a46')]


for cur in collection.find():
print(cur)
{'4': 'vl', '2': 3, '3': 'male', '1': 39, '_id':
ObjectId('557da218f21c761d7c176
a40'), '0': 'Vinh'}
{'4': 'dn', '2': 3, '3': 'male', '1': 26, '_id':
ObjectId('557da218f21c761d7c176
a41'), '0': 'Nghia'}
{'4': 'dn', '2': 4, '3': 'female', '1': 28, '_id':
ObjectId('557da218f21c761d7c1
76a42'), '0': 'Hong'}
{'4': 'hn', '2': 3, '3': 'female', '1': 25, '_id':
ObjectId('557da218f21c761d7c1
76a43'), '0': 'Lan'}
{'4': 'tn', '2': 3, '3': 'male', '1': 42, '_id':
ObjectId('557da218f21c761d7c176
a44'), '0': 'Hung'}
{'4': 'hcm', '2': 1, '3': 'male', '1': 7, '_id':
ObjectId('557da218f21c761d7c176
a45'), '0': 'Nam'}
{'4': 'hcm', '2': 1, '3': 'female', '1': 11, '_id':
ObjectId('557da218f21c761d7c
176a46'), '0': 'Mai'}
         
         


cur = collection.find({'3' : 'male'})
type(cur)
pymongo.cursor.Cursor
result = pd.DataFrame(list(cur))
result

# before removing data
pd.DataFrame(list(collection.find()))        
# after removing records which have '2' column as 1 and '3' column as
'male'
collection.remove({'2': 1, '3': 'male'})
{'n': 1, 'ok': 1}
cur_all = collection.find();
pd.DataFrame(list(cur_all))
        
         
doc = collection.find_one({'1' : 42})
doc['4'] = 'hcm'
collection.save(doc)
ObjectId('557da218f21c761d7c176a44')
pd.DataFrame(list(collection.find()))
         
         
#Interacting with data in Redis
         
         
import redis
r = redis.StrictRedis(host='127.0.0.1', port=6379)
r

#The simple value
         
         
r.set('gender:An', 'male')
True
r.get('gender:An')
         
         
r.set('visited_time:An', 12)
True
r.get('visited_time:An')
b'12'
r.incr('visited_time:An', 1)
13
r.get('visited_time:An')
b'13'
         
#List
         
r.rpush('name_list', 'Tom')
1L
r.rpush('name_list', 'John')
2L
r.rpush('name_list', 'Mary')
3L
r.rpush('name_list', 'Jan')
4L
r.lrange('name_list', 0, -1)
[b'Tom', b'John', b'Mary', b'Jan']
r.llen('name_list')
4
r.lindex('name_list', 1)
b'John'
         
#Set
         
r.sadd('country', 'USA')
1
r.sadd('country', 'Italy')
1
r.sadd('country', 'Singapore')
1
r.sadd('country', 'Singapore')
0
r.smembers('country')
{b'Italy', b'Singapore', b'USA'}
r.srem('country', 'Singapore')
1
r.smembers('country')
{b'Italy', b'USA'}
         
#Ordered Set
     
r.zadd('person:A', 10, 'sub:Math')
1
r.zadd('person:A', 7, 'sub:Bio')
1
r.zadd('person:A', 8, 'sub:Chem')
1
r.zrange('person:A', 0, -1)
[b'sub:Bio', b'sub:Chem', b'sub:Math']
r.zrange('person:A', 0, -1, withscores=True)
[(b'sub:Bio', 7.0), (b'sub:Chem', 8.0), (b'sub:Math', 10.0)]



#Chapter7- Data Analysis Application Examples


#Cleaning Data

import pandas as pd
df = pd.read_csv("small.csv")
df


df = pd.read_csv("small.csv", header=None)
df

df = pd.read_csv("small.csv", names=["age", "height"])
df


df.age.dtype
dtype('int64')
df.height.dtype
dtype('O')

df.height.astype('float')

df.height.convert_objects(convert_numeric=True)

remove_stars = lambda s: s.replace("*", "")
df = pd.read_csv("small.csv", names=["age", "height"],
converters={"height": remove_stars})
df

df.height = df.height.convert_objects(convert_numeric=True)
df

df.dropna()

df.fillna(5.0)

df.fillna(df.height.mean())


#Filtering

df.head()

df.tail()

df[df.price==df.price.min()]


df[df.price==df.price.max()]


np.abs(df.price - df.price.mean())

import numpy as np
df[np.abs(df.price - df.price.mean()) > 2.5 * df.price.std()]


df.index = df.date
del df["date"]
df.head()

decade = df["1980":"1989"]
decade[np.abs(decade.price - decade.price.mean()) > 2.5 * decade.
price.std()]

decade = df["1990":"1999"]
decade[np.abs(decade.price - decade.price.mean()) > 5 * decade.price.
std()]

#Merging Data

df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
df1



df2 = pd.DataFrame({'A': [4, 5, 6], 'B': [7, 8, 9]})
df2

df1.append(df2)

df1.append(df2, ignore_index=True)

pd.concat([df1, df2])

pd.concat([df1, df2], axis=1)

pd.concat([df1, df2], keys=['UK', 'DE'])

df3 = pd.concat([df1, df2], keys=['UK', 'DE'])
df3.ix["UK"]

import numpy as np
df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],
'value': range(4)})
df1


df2 = pd.DataFrame({'key': ['B', 'D', 'D', 'E'],
'value': range(10, 14)})
df2

df1.merge(df2, on='key')

df1.merge(df2, on='key', how='left')

df1.merge(df2, on='key', how='right')

df1.merge(df2, on='key', how='outer')

#Reshaping Data

df

df.groupby('city').max()

pv = df.pivot("date", "city", "value")
pv

pv.max()

pv.max(axis=1)



#Data Aggregation

df.head()

df.groupby("city").describe()

df.groupby(["country", "date"]).describe()

df.groupby("city").mean()

df.groupby("city").agg(np.mean)

df.groupby("city").agg(lambda s: abs(min(s) - max(s)))


#Grouping Data

df

df.groupby("city").groups

grouped = df.groupby(["city", "value"])
grouped["value"].max()

grouped["value"].sum()

df['value'].groupby(df['city']).sum()

#Chapter-8 Machine learning models with scikit learn

import numpy as np
from sklearn import datasets
iris = datasets.load_iris()

type(iris)
sklearn.datasets.base.Bunch
iris.keys()
['target_names', 'data', 'target', 'DESCR', 'feature_names']

type(iris.data)
numpy.ndarray
iris.data.shape (150, 4)

type(iris.target)
numpy.ndarray
iris.target.shape (150,)

iris.target[:10]
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
np.unique(iris.target)
array([0, 1, 2])

iris.target_names
array(['setosa', 'versicolor', 'virginica'], dtype='|S10')

iris.data[0]
array([ 5.1, 3.5, 1.4, 0.2])


ds = datasets.fetch_california_housing()
downloading Cal. housing from http://lib.stat.cmu.edu/modules.php?op=...
ds.data.shape (20640, 8)
ds = datasets.fetch_20newsgroups()
len(ds.data)
11314
ds.data[0][:50]

sum([len([w for w in sample.split()]) for sample in ds.data])
3252437


from sklearn.svm import SVC
clf = SVC(probability=True)


clf.fit(iris.data, iris.target)
SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0, kernel='rbf', max_iter=-1, probability=True, random_state=None, shrinking=True,
tol=0.001, verbose=False)

unseen = [6.0, 2.0, 3.0, 2.0]
clf.predict(unseen)
array([1])
iris.target_names[clf.predict(unseen)]
array(['versicolor'],
dtype='|S10')

clf.predict_proba(unseen)

import matplotlib.pyplot as plt
X = [[1], [2], [3], [4], [5], [6], [7], [8]]
y = [1, 2.5, 3.5, 4.8, 3.9, 5.5, 7, 8]
plt.scatter(X, y, c='0.25')
plt.show()

from sklearn.linear_model import LinearRegression
clf = LinearRegression()
clf.fit(X, y)

clf.coef_
plt.plot(X, clf.predict(X), '--', color='0.10', linewidth=1)


from sklearn.cluster import KMeans
km = KMeans(n_clusters=3)

km.fit(iris.data)


km.labels_

iris.target

tr = {1: 0, 2: 1, 0: 2}
predicted_labels = np.array([tr[i] for i in km.labels_])
sum([p == t for (p, t) in zip(predicted_labels, iris.target)])
134

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

pca = PCA(n_components=2)
X = StandardScaler().fit_transform(iris.data)
Y = pca.fit_transform(X)


from sklearn.cross_validation import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
iris.data, iris.target, test_size=0.4, random_state=0)
clf = SVC()
clf.fit(X_train, y_train)


clf.score(X_test, y_test)

from sklearn.cross_validation import cross_val_score
clf = SVC()
scores = cross_val_score(clf, iris.data, iris.target, cv=5)
scores
array([ 0.96666667, 1. , 0.96666667, 0.96666667, 1. ])
scores.mean()





